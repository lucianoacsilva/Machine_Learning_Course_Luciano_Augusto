{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = read.csv('Wine.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide the dataset in training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caTools)\n",
    "set.seed(123)\n",
    "split = sample.split(dataset$Customer_Segment, SplitRatio = 0.8)\n",
    "training_set = subset(dataset, split == TRUE)\n",
    "test_set = subset(dataset, split == FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in colMeans(x, na.rm = TRUE): 'x' deve ser numérico\n",
     "output_type": "error",
     "traceback": [
      "Error in colMeans(x, na.rm = TRUE): 'x' deve ser numérico\nTraceback:\n",
      "1. scale(test_set[-14])",
      "2. scale.default(test_set[-14])",
      "3. colMeans(x, na.rm = TRUE)"
     ]
    }
   ],
   "source": [
    "training_set[-14] = scale(training_set[-14])\n",
    "test_set[-14] = scale(test_set[-14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying LDA on Training Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(MASS)\n",
    "lda = lda(formula = Customer_Segment ~ ., data = training_set)\n",
    "training_set = as.data.frame(predict(lda, training_set))\n",
    "training_set = training_set[c(5, 6, 1)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, on the Test Set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = as.data.frame(predict(lda, test_set))\n",
    "test_set = test_set[c(5, 6, 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting SVM to the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(e1071)\n",
    "classifier = svm(formula = class ~ .,\n",
    "                 data = training_set,\n",
    "                 type = 'C-classification',\n",
    "                 kernel = 'linear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predicting results in the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = predict(classifier, newdata = test_set[-3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = table(test_set[, 3], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing Training Set resuts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in plot.default(...): argumento formal \"xlab\" corresponde a múltiplos argumentos especificados\n",
     "output_type": "error",
     "traceback": [
      "Error in plot.default(...): argumento formal \"xlab\" corresponde a múltiplos argumentos especificados\nTraceback:\n",
      "1. plot(set[, -3], main = \"SVM (Training set)\", xlab = \"x.LD1\", \n .     ylab = \"x.LD2\", xlim = range(X1), ylim = range(X2))",
      "2. plot.data.frame(set[, -3], main = \"SVM (Training set)\", xlab = \"x.LD1\", \n .     ylab = \"x.LD2\", xlim = range(X1), ylim = range(X2))",
      "3. pairs(data.matrix(x), ...)",
      "4. pairs.default(data.matrix(x), ...)",
      "5. localPlot(x[, j], x[, i], xlab = \"\", ylab = \"\", axes = FALSE, \n .     type = \"n\", ..., log = l)",
      "6. plot(...)"
     ]
    }
   ],
   "source": [
    "library(ElemStatLearn)\n",
    "set = training_set\n",
    "X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)\n",
    "X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)\n",
    "grid_set = expand.grid(X1, X2)\n",
    "colnames(grid_set) = c('x.LD1', 'x.LD2')\n",
    "y_grid = predict(classifier, newdata = grid_set)\n",
    "plot(set[, -3],\n",
    "     main = 'SVM (Training set)',\n",
    "     xlab = 'x.LD1', ylab = 'x.LD2',\n",
    "     xlim = range(X1), ylim = range(X2))\n",
    "contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)\n",
    "points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))\n",
    "points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the Test Set results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ElemStatLearn)\n",
    "set = test_set\n",
    "X1 = seq(min(set[, 1]) - 1, max(set[, 1]) + 1, by = 0.01)\n",
    "X2 = seq(min(set[, 2]) - 1, max(set[, 2]) + 1, by = 0.01)\n",
    "grid_set = expand.grid(X1, X2)\n",
    "colnames(grid_set) = c('x.LD1', 'x.LD2')\n",
    "y_grid = predict(classifier, newdata = grid_set)\n",
    "plot(set[, -3], main = 'SVM (Test set)',\n",
    "     xlab = 'x.LD1', ylab = 'x.LD2',\n",
    "     xlim = range(X1), ylim = range(X2))\n",
    "contour(X1, X2, matrix(as.numeric(y_grid), length(X1), length(X2)), add = TRUE)\n",
    "points(grid_set, pch = '.', col = ifelse(y_grid == 2, 'deepskyblue', ifelse(y_grid == 1, 'springgreen3', 'tomato')))\n",
    "points(set, pch = 21, bg = ifelse(set[, 3] == 2, 'blue3', ifelse(set[, 3] == 1, 'green4', 'red3')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   y_pred\n",
       "     1  2  3\n",
       "  1 12  0  0\n",
       "  2  1 13  0\n",
       "  3  0  0 10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
